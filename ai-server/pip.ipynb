{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.29-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.9.5-cp311-cp311-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
      "  Using cached langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
      "  Using cached langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.1.48-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Using cached pydantic-2.7.0-py3-none-any.whl.metadata (103 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp311-cp311-win_amd64.whl.metadata (32 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.1-cp311-none-win_amd64.whl.metadata (50 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.1 (from pydantic<3,>=1->langchain)\n",
      "  Using cached pydantic_core-2.18.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.0.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Using cached langchain-0.1.16-py3-none-any.whl (817 kB)\n",
      "Using cached aiohttp-3.9.5-cp311-cp311-win_amd64.whl (370 kB)\n",
      "Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_community-0.0.33-py3-none-any.whl (1.9 MB)\n",
      "Using cached langchain_core-0.1.44-py3-none-any.whl (290 kB)\n",
      "Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Using cached langsmith-0.1.48-py3-none-any.whl (113 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Using cached pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "Using cached pydantic_core-2.18.1-cp311-none-win_amd64.whl (1.9 MB)\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "Using cached SQLAlchemy-2.0.29-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "Using cached greenlet-3.0.3-cp311-cp311-win_amd64.whl (292 kB)\n",
      "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.0.5-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Using cached orjson-3.10.1-cp311-none-win_amd64.whl (139 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, PyYAML, pydantic-core, packaging, orjson, numpy, mypy-extensions, multidict, jsonpointer, greenlet, frozenlist, attrs, annotated-types, yarl, typing-inspect, SQLAlchemy, pydantic, marshmallow, jsonpatch, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.29 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.6.0 attrs-23.2.0 dataclasses-json-0.6.4 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.33 langchain-core-0.1.44 langchain-text-splitters-0.0.1 langsmith-0.1.48 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.1 packaging-23.2 pydantic-2.7.0 pydantic-core-2.18.1 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.4\n",
      "Collecting openai\n",
      "  Using cached openai-1.23.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from openai) (2.7.0)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
      "Requirement already satisfied: colorama in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-1.23.1-py3-none-any.whl (310 kB)\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: tqdm, sniffio, h11, distro, httpcore, anyio, httpx, openai\n",
      "Successfully installed anyio-4.3.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.23.1 sniffio-1.3.1 tqdm-4.66.2\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.6.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.4.16-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/42.0 kB 320.0 kB/s eta 0:00:01\n",
      "     -------------------------------------  41.0/42.0 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.0/42.0 kB 337.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Using cached tiktoken-0.6.0-cp311-cp311-win_amd64.whl (798 kB)\n",
      "Downloading regex-2024.4.16-cp311-cp311-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.9 kB ? eta -:--:--\n",
      "   -------------------------------------- - 256.0/268.9 kB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 268.9/268.9 kB 5.5 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.4.16 tiktoken-0.6.0\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from chromadb) (2.7.0)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.3-cp311-cp311-win_amd64.whl.metadata (262 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Using cached fastapi-0.110.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from chromadb) (4.11.0)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Downloading pulsar_client-3.5.0-cp311-cp311-win_amd64.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.17.3-cp311-cp311-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_api-1.24.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from chromadb) (4.66.2)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.62.2-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Using cached bcrypt-4.1.2-cp39-abi3-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Using cached typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Using cached kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Using cached mmh3-4.1.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from chromadb) (3.10.1)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.26.1-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached importlib_metadata-7.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Using cached opentelemetry_proto-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached opentelemetry_util_http-0.45b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (65.5.0)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests>=2.28->chromadb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests>=2.28->chromadb) (3.7)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
      "  Using cached huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached httptools-0.6.1-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached watchfiles-0.21.0-cp311-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached websockets-12.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Using cached filelock-3.13.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Using cached zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.17.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (4.3.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.3.1)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Using cached chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "Using cached chroma_hnswlib-0.7.3-cp311-cp311-win_amd64.whl (151 kB)\n",
      "Using cached bcrypt-4.1.2-cp39-abi3-win_amd64.whl (158 kB)\n",
      "Using cached build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
      "Downloading grpcio-1.62.2-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/3.8 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 1.1/3.8 MB 14.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.9/3.8 MB 15.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.2/3.8 MB 12.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.6/3.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.8/3.8 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.2/3.8 MB 10.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.4/3.8 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 8.9 MB/s eta 0:00:00\n",
      "Using cached kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Using cached mmh3-4.1.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Downloading onnxruntime-1.17.3-cp311-cp311-win_amd64.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.6 MB 22.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.4/5.6 MB 14.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.5/5.6 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.9/5.6 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.2/5.6 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.6/5.6 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.9/5.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.1/5.6 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.5/5.6 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.6 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.1/5.6 MB 7.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.7/5.6 MB 7.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.8/5.6 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.2/5.6 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.5/5.6 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 7.2 MB/s eta 0:00:00\n",
      "Using cached opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
      "Using cached opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
      "Using cached opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
      "Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "Downloading pulsar_client-3.5.0-cp311-cp311-win_amd64.whl (3.3 MB)\n",
      "   ---------------------------------------- 0.0/3.3 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.6/3.3 MB 48.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.9/3.3 MB 24.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.1/3.3 MB 15.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.5/3.3 MB 14.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.7/3.3 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.1/3.3 MB 10.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.2/3.3 MB 9.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.2/3.3 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.3/3.3 MB 8.1 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.2 MB 25.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.2 MB 26.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.5/2.2 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.2 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 9.4 MB/s eta 0:00:00\n",
      "Using cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "Using cached uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached httptools-0.6.1-cp311-cp311-win_amd64.whl (55 kB)\n",
      "Using cached huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "Using cached importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "Using cached watchfiles-0.21.0-cp311-none-win_amd64.whl (280 kB)\n",
      "Using cached websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "Using cached websockets-12.0-cp311-cp311-win_amd64.whl (124 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Using cached zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Using cached filelock-3.13.4-py3-none-any.whl (11 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Installing collected packages: pyreadline3, pypika, mpmath, monotonic, mmh3, flatbuffers, zipp, wrapt, websockets, websocket-client, sympy, shellingham, python-dotenv, pyproject_hooks, pyasn1, pulsar-client, protobuf, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, oauthlib, mdurl, importlib-resources, humanfriendly, httptools, grpcio, fsspec, filelock, click, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, huggingface-hub, googleapis-common-protos, deprecated, coloredlogs, build, tokenizers, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, google-auth, fastapi, typer, opentelemetry-sdk, opentelemetry-instrumentation, kubernetes, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.2 build-1.2.1 cachetools-5.3.3 chroma-hnswlib-0.7.3 chromadb-0.4.24 click-8.1.7 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.110.1 filelock-3.13.4 flatbuffers-24.3.25 fsspec-2024.3.1 google-auth-2.29.0 googleapis-common-protos-1.63.0 grpcio-1.62.2 httptools-0.6.1 huggingface-hub-0.22.2 humanfriendly-10.0 importlib-metadata-7.0.0 importlib-resources-6.4.0 kubernetes-29.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 oauthlib-3.2.2 onnxruntime-1.17.3 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 overrides-7.7.0 posthog-3.5.0 protobuf-4.25.3 pulsar-client-3.5.0 pyasn1-0.6.0 pyasn1-modules-0.4.0 pypika-0.48.9 pyproject_hooks-1.0.0 pyreadline3-3.4.1 python-dotenv-1.0.1 requests-oauthlib-2.0.0 rich-13.7.1 rsa-4.9 shellingham-1.5.4 starlette-0.37.2 sympy-1.12 tokenizers-0.19.1 typer-0.12.3 uvicorn-0.29.0 watchfiles-0.21.0 websocket-client-1.7.0 websockets-12.0 wrapt-1.16.0 zipp-3.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install tiktoken\n",
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (0.0.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-community) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-community) (0.6.4)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.43 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-community) (0.1.44)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-community) (0.1.48)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.43->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.43->langchain-community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.43->langchain-community) (2.7.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.43->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.43->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.43->langchain-community) (2.18.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = 'sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-openai) (0.1.44)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-openai) (1.23.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (0.1.48)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.7.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2024.4.16)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain-openai) (3.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai) (0.4.6)\n",
      "Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: langchain-openai\n",
      "Successfully installed langchain-openai-0.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\durham college\\aidi\\term 2\\202441.11553-aidi-2001-01 - knowledge and exp systems\\final-project\\web-shepherd\\.venv\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Using cached faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl (14.5 MB)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='import Clientfrom langsmith.evaluation import evaluateclient = Client()# Define dataset: these are your test casesdataset_name = \"Sample Dataset\"dataset = client.create_dataset(dataset_name, description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"output\": \"Welcome to LangSmith\"},        {\"output\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):    return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(    lambda input: \"Welcome \" + input[\\'postfix\\'], # Your AI system goes here    data=dataset_name, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\":', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith |  LangSmith', 'description': 'Introduction', 'language': 'en'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"how to upload a dataset\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "  [(\"system\", \"You are a helpful assistant\"),\n",
    "  (\"placeholder\", \"{chat_history}\"),\n",
    "  (\"human\", \"{input}\"),\n",
    "  (\"placeholder\", \"{agent_scratchpad}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad', optional=True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'how can LangSmith help with testing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mGetting started with LangSmith |  LangSmith\n",
      "\n",
      "Skip to main contentLangSmith API DocsSearchGo to AppQuick StartUser GuideTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyPricingSelf-HostingCookbookQuick StartOn this pageGetting started with LangSmithIntroductionLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!Install LangSmithWe offer Python and Typescript SDKs for all your LangSmith needs.PythonTypeScriptpip install -U langsmithyarn add langchain langsmithCreate an API keyTo create an API key head to the setting pages. Then click Create API Key.Setup your environmentShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>Log your first traceWe provide multiple ways to log traces\n",
      "\n",
      "Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Proxy: Learn about the proxy capabilities of LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional ResourcesLangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!FAQHow do I migrate projects between organizations?Currently we do not support project migration betwen organizations. While you can manually imitate this by\n",
      "\n",
      "team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?If you are interested in a private deployment of LangSmith or if you need to self-host, please reach out to us at sales@langchain.dev. Self-hosting LangSmith requires an annual enterprise license that also comes with support and formalized access to the LangChain team.Was this page helpful?NextUser GuideIntroductionInstall LangSmithCreate an API keySetup your environmentLog your first traceCreate your first evaluationNext StepsAdditional ResourcesFAQHow do I migrate projects between organizations?Why aren't my runs aren't showing up in my project?My team deals with sensitive data that cannot be logged. How can I ensure that only my team can access it?CommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright  2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith can help with testing by providing capabilities for tracing, evaluation, production monitoring, and automations. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. LangSmith offers tracing capabilities, evaluation features, and supports workflows at each stage of the LLM application lifecycle. Additionally, LangSmith provides a Prompt Hub for prompt management and supports self-hosting options for those who require it.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': 'LangSmith can help with testing by providing capabilities for tracing, evaluation, production monitoring, and automations. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. LangSmith offers tracing capabilities, evaluation features, and supports workflows at each stage of the LLM application lifecycle. Additionally, LangSmith provides a Prompt Hub for prompt management and supports self-hosting options for those who require it.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! I'm bob\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"hi! I'm bob\",\n",
       " 'chat_history': [HumanMessage(content=\"hi! I'm bob\"),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob! How can I assist you today, Bob?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name?\",\n",
       " 'chat_history': [HumanMessage(content=\"hi! I'm bob\"),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?'),\n",
       "  HumanMessage(content=\"hi! I'm bob\"),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'output': 'Your name is Bob! How can I assist you today, Bob?'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"what's my name?\"},\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
